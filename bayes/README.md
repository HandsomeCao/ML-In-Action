## 朴素贝叶斯

### 贝叶斯决策理论
我们现在用p1(x,y)表示数据点(x,y)属于类别1的概率，用p2(x,y)表示数据点(x,y)属于类别2（图中用三角形表示的类别）的概率，那么对于一个新数据点(x,y)，可以用下面的规则来判断它的类别：
* 如果 p1(x,y) > p2(x,y)，那么类别为1。
* 如果 p2(x,y) > p1(x,y)，那么类别为2。

也就是说，我们会选择高概率对应的类别。这就是贝叶斯决策理论的核心思想，即选择具有最高概率的决策。

### 使用朴素贝叶斯进行分类
1. 收集数据
2. 准备数据：需要数值型数据或者布尔型数据
3. 分析数据：有大量特征时，绘制特征作用不大，此时使用直方图效果更好。
4. 训练算法：计算不同的独立特征的条件概率
5. 测试算法：计算错误率
6. 使用算法：一个常见的朴素贝叶斯应用是文档分类。可以在任意的分类场景中使用朴素贝叶斯分类器，不一定非要是文本。


### 训练算法

$$p(c_{i}|w) = \frac{p(w|c_{i})p(c_{i})}{p(w)}$$

其中c为类别， w表示向量。首先可以通过类别i（侮辱性留言或非侮辱性留言）中文档数除以总的文档数来计算概率p(ci)。接下来计算$p(w|ci)$，这里就要用到朴素贝叶斯假设。如果将w展开为一个个独立特征，那么就可以将上述概率写作$p(w0,w1,w2..wN|ci)$。这里假设所有词都互相独立，该假设也称作条件独立性假设，它意味着可以使用$p(w0|ci)p(w1|ci)p(w2|ci)...p(wN|ci)$来计算上述概率，这就极大地简化了计算的过程。

